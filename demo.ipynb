{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44328d25",
   "metadata": {},
   "source": [
    "# Elastic Self-Managed GPU Acceleration Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421faf3",
   "metadata": {},
   "source": [
    "## Create GKE Cluster + GPU Node Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7907e8e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).\n",
      "Creating cluster gpu-demo in us-central1...\n",
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Created [https://container.googleapis.com/v1/projects/elastic-customer-eng/zones/us-central1/clusters/gpu-demo].\n",
      "To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1/gpu-demo?project=elastic-customer-eng\n",
      "kubeconfig entry generated for gpu-demo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      LOCATION     MASTER_VERSION      MASTER_IP     MACHINE_TYPE   NODE_VERSION        NUM_NODES  STATUS   STACK_TYPE\n",
      "gpu-demo  us-central1  1.33.5-gke.2019000  34.69.112.19  e2-standard-4  1.33.5-gke.2019000  3          RUNNING  IPV4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Machines with GPUs have certain limitations which may affect your workflow. Learn more at https://cloud.google.com/kubernetes-engine/docs/how-to/gpus\n",
      "Note: Starting in GKE 1.30.1-gke.115600, if you don't specify a driver version, GKE installs the default GPU driver for your node's GKE version.\n",
      "Creating node pool gpu-pool...\n",
      "....................................................................................................................................................................................................................................................................................................................done.\n",
      "Created [https://container.googleapis.com/v1/projects/elastic-customer-eng/zones/us-central1/clusters/gpu-demo/nodePools/gpu-pool].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      MACHINE_TYPE   DISK_SIZE_GB  NODE_VERSION\n",
      "gpu-pool  g2-standard-4  100           1.33.5-gke.2019000\n",
      "NODE                                      ZONE\n",
      "gke-gpu-demo-default-pool-39f74ae9-38lq   us-central1-a\n",
      "gke-gpu-demo-default-pool-6863c142-8wtn   us-central1-b\n",
      "gke-gpu-demo-default-pool-ba602fca-gvpp   us-central1-c\n",
      "gke-gpu-demo-gpu-pool-4de4e479-9vt9       us-central1-c\n",
      "gke-gpu-demo-gpu-pool-855f47e1-gnt5       us-central1-a\n",
      "gke-gpu-demo-gpu-pool-e436ad48-7cxs       us-central1-b\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud container clusters create gpu-demo \\\n",
    "    --region us-central1 \\\n",
    "    --node-locations us-central1-a,us-central1-b,us-central1-c \\\n",
    "    --num-nodes 1 \\\n",
    "    --machine-type e2-standard-4 \\\n",
    "    --disk-type pd-standard \\\n",
    "    --disk-size 50GB\n",
    "\n",
    "gcloud container node-pools create gpu-pool \\\n",
    "    --cluster gpu-demo \\\n",
    "    --region us-central1 \\\n",
    "    --node-locations us-central1-a,us-central1-b,us-central1-c \\\n",
    "    --num-nodes 1 \\\n",
    "    --machine-type g2-standard-4 \\\n",
    "    --disk-type pd-ssd \\\n",
    "    --disk-size 100GB \\\n",
    "    --accelerator type=nvidia-l4,count=1,gpu-driver-version=latest \\\n",
    "    --location-policy ANY \\\n",
    "    --spot\n",
    "\n",
    "kubectl get nodes -o custom-columns=\"NODE:.metadata.name,ZONE:.metadata.labels.topology\\.kubernetes\\.io/zone\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32287b7d",
   "metadata": {},
   "source": [
    "## Deploy Elastic Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "453dde40",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/eck-trial-license unchanged\n",
      "elasticsearch.elasticsearch.k8s.elastic.co/elastic configured\n",
      "kibana.kibana.k8s.elastic.co/kibana configured\n",
      "\n",
      "Pod: elastic-es-data-node-0        Zone: us-central1-a    Node: gke-gpu-demo-gpu-pool-855f47e1-gnt5\n",
      "Pod: elastic-es-data-node-1        Zone: us-central1-c    Node: gke-gpu-demo-gpu-pool-4de4e479-9vt9\n",
      "Pod: elastic-es-data-node-2        Zone: us-central1-b    Node: gke-gpu-demo-gpu-pool-e436ad48-7cxs\n",
      "Pod: elastic-es-master-node-0      Zone: us-central1-c    Node: gke-gpu-demo-default-pool-ba602fca-gvpp\n",
      "Pod: elastic-es-master-node-1      Zone: us-central1-a    Node: gke-gpu-demo-default-pool-39f74ae9-38lq\n",
      "Pod: elastic-es-master-node-2      Zone: us-central1-b    Node: gke-gpu-demo-default-pool-6863c142-8wtn\n",
      "Pod: kibana-kb-68895889d5-wl9vk    Zone: us-central1-c    Node: gke-gpu-demo-default-pool-ba602fca-gvpp\n",
      "Pod: kibana-kb-6d7cd49cd4-rzmdd    Zone: us-central1-b    Node: gke-gpu-demo-default-pool-6863c142-8wtn\n",
      "\n",
      "Kibana is available at: https://34.41.38.142:5601\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create -f https://download.elastic.co/downloads/eck/3.2.0/crds.yaml > /dev/null 2>&1\n",
    "kubectl apply -f https://download.elastic.co/downloads/eck/3.2.0/operator.yaml > /dev/null 2>&1\n",
    "kubectl apply -f manifests\n",
    "ES_STATUS=$(kubectl get elasticsearch -o=jsonpath='{.items[0].status.health}')\n",
    "KB_STATUS=$(kubectl get kibana -o=jsonpath='{.items[0].status.health}')\n",
    "while [[ $ES_STATUS != \"green\" ||  $KB_STATUS != \"green\" ]]\n",
    "do  \n",
    "  sleep 5\n",
    "  ES_STATUS=$(kubectl get elasticsearch -o=jsonpath='{.items[0].status.health}')\n",
    "  KB_STATUS=$(kubectl get kibana -o=jsonpath='{.items[0].status.health}')\n",
    "done\n",
    "\n",
    "cat > .env << EOF\n",
    "ELASTIC_USERNAME=elastic\n",
    "ELASTIC_PASSWORD=$(kubectl get secret elastic-es-elastic-user -o go-template='{{.data.elastic | base64decode}}')\n",
    "ELASTIC_URL=https://$(kubectl get svc elastic-es-http -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):9200\n",
    "EOF\n",
    "\n",
    "cat .api_keys >> .env 2>/dev/null\n",
    "kubectl get secret elastic-es-http-certs-public -o jsonpath='{.data.ca\\.crt}' | base64 --decode > ca.crt\n",
    "\n",
    "echo\n",
    "kubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.nodeName}{\"\\t\"}{.metadata.labels.app}{\"\\n\"}{end}' | while read pod node app; do\n",
    "    zone=$(kubectl get node $node -o jsonpath='{.metadata.labels.topology\\.kubernetes\\.io/zone}')\n",
    "    echo \"Pod: $pod | Zone: $zone | Node: $node\"\n",
    "done | column -t -s \"|\"\n",
    "echo\n",
    "echo \"Kibana is available at: https://$(kubectl get svc kibana-kb-http -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):5601\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866a0e9",
   "metadata": {},
   "source": [
    "## Create Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from faker import Faker\n",
    "#import requests \n",
    "#from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import time\n",
    "import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "DATASET_SIZE = 10000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "load_dotenv(override=True)\n",
    "es = Elasticsearch(\n",
    "    hosts=os.getenv(\"ELASTIC_URL\"),\n",
    "    basic_auth=(os.getenv(\"ELASTIC_USERNAME\"), os.getenv(\"ELASTIC_PASSWORD\")),\n",
    "    ca_certs=\"./ca.crt\",\n",
    "    max_retries=10,\n",
    "    retry_on_timeout=True\n",
    ")\n",
    "\n",
    "es.options(ignore_status=[404]).inference.delete(inference_id=\"jina-embeddings-v3\")\n",
    "response = es.inference.put(\n",
    "    task_type=\"text_embedding\",\n",
    "    inference_id=\"jina-embeddings-v3\",\n",
    "    body={\n",
    "        \"service\": \"jinaai\",\n",
    "        \"service_settings\": {\n",
    "            \"api_key\": os.getenv(\"JINA_API_KEY\"),\n",
    "            \"model_id\": \"jina-embeddings-v3\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "def get_jina_embeddings(batch):\n",
    "    response = es.inference.inference(input=batch, inference_id=\"jina-embeddings-v3\")\n",
    "    return [item['embedding'] for item in response['text_embedding']]\n",
    "'''\n",
    "class RateLimitError(Exception):\n",
    "    pass\n",
    "\n",
    "@retry(\n",
    "        wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "        stop=stop_after_attempt(5),\n",
    "        retry=retry_if_exception_type(RateLimitError)\n",
    ")\n",
    "def get_jina_embeddings(batch):\n",
    "    url = \"https://api.jina.ai/v1/embeddings\"\n",
    "    headers = { \n",
    "        \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\", \n",
    "        \"Content-Type\": \"application/json\" \n",
    "    }\n",
    "    payload = { \n",
    "        \"model\": \"jina-embeddings-v3\", \n",
    "        \"task\": \"text-matching\",\n",
    "        \"input\": batch\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 429:\n",
    "        raise RateLimitError(\"Rate limit exceeded\")\n",
    "    response.raise_for_status()\n",
    "    return [item['embedding'] for item in response.json()['data']]\n",
    "'''\n",
    "def create_data_file():\n",
    "    fake = Faker()\n",
    "    fake.seed_instance(12345)\n",
    "\n",
    "    with open(\"data.jsonl\", \"w\") as f:\n",
    "        for _ in tqdm.tqdm(range(DATASET_SIZE // BATCH_SIZE)):\n",
    "            paragraphs = fake.paragraphs(nb=BATCH_SIZE)\n",
    "            embeddings = get_jina_embeddings(paragraphs)\n",
    "            for paragraph, embedding in zip(paragraphs, embeddings):\n",
    "                doc = {\"paragraph\": paragraph, \"embedding\": embedding}\n",
    "                f.write(json.dumps(doc) + \"\\n\")\n",
    "            time.sleep(1) \n",
    "\n",
    "if not os.path.exists(\"data.jsonl\"):\n",
    "    create_data_file()\n",
    "\n",
    "with open(\"data.jsonl\", \"r\") as f:\n",
    "    line_count = sum(1 for _ in f)\n",
    "print(f'{line_count} documents on file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bce783",
   "metadata": {},
   "source": [
    "## Index Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb80187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "INDEX_NAME = \"test_index\"\n",
    "#es = Elasticsearch(\n",
    "#    hosts=os.getenv(\"ELASTIC_URL\"),\n",
    "#    basic_auth=(os.getenv(\"ELASTIC_USERNAME\"), os.getenv(\"ELASTIC_PASSWORD\")),\n",
    "#    ca_certs=\"./ca.crt\",\n",
    "#    max_retries=10,\n",
    "#    retry_on_timeout=True\n",
    "#)\n",
    "\n",
    "settings = {\n",
    "    \"index\": {\n",
    "        \"number_of_shards\": 3,\n",
    "        \"number_of_replicas\": 1\n",
    "    }\n",
    "}\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"paragraph\": { \"type\": \"text\" },\n",
    "        \"embedding\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 1024,\n",
    "            \"index\": True,\n",
    "            \"index_options\": {\n",
    "                \"type\": \"int8_hnsw\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}            \n",
    "\n",
    "es.options(ignore_status=[404]).indices.delete(index=INDEX_NAME)\n",
    "es.indices.create(index=INDEX_NAME, body={\"settings\": settings, \"mappings\": mappings})\n",
    "\n",
    "def gen_data():\n",
    "    with open(\"data.jsonl\", \"r\") as f:\n",
    "        for line in f:\n",
    "            yield line.strip()\n",
    "            \n",
    "ok, result = helpers.bulk(client=es.options(request_timeout=60), \n",
    "                          index=INDEX_NAME, \n",
    "                          actions=gen_data())\n",
    "print(f\"{ok} documents indexed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708c495",
   "metadata": {},
   "source": [
    "## Reindex Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6529cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*technical preview.*\")\n",
    "\n",
    "def monitor_reindex(task_id):\n",
    "    while True:\n",
    "        task = es.tasks.get(task_id=task_id)\n",
    "        completed = task.get('completed', False)\n",
    "        if completed:\n",
    "            latency_sec = task['response']['took'] / 1000\n",
    "            total_docs = task['response']['total']\n",
    "            throughput = total_docs / latency_sec\n",
    "            return latency_sec, throughput\n",
    "        time.sleep(2)\n",
    "            \n",
    "def speed_test(tests=10):\n",
    "    latencies = []\n",
    "    throughputs = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(tests)):\n",
    "        es.indices.clear_cache(index=INDEX_NAME)\n",
    "        dest = f\"{INDEX_NAME}_{uuid.uuid4()}\"\n",
    "        reindex_body = {\n",
    "            \"source\": { \"index\": INDEX_NAME },\n",
    "            \"dest\": { \"index\": dest }\n",
    "        }\n",
    "        response = es.reindex(slices=\"auto\", body=reindex_body, wait_for_completion=False)\n",
    "        task_id = response['task']\n",
    "        latency, throughput = monitor_reindex(task_id)\n",
    "        latencies.append(latency)\n",
    "        throughputs.append(throughput)\n",
    "        es.indices.delete(index=dest)\n",
    "        if i < tests - 1:\n",
    "            time.sleep(5)\n",
    "    return latencies, throughputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f753b70",
   "metadata": {},
   "source": [
    "## CPU Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af28637",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_latencies, cpu_throughputs = speed_test()\n",
    "print('Latencies:', cpu_latencies)\n",
    "print('Throughputs:', cpu_throughputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c638f",
   "metadata": {},
   "source": [
    "## Reconfigure for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f213b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl patch elasticsearch elastic --type='merge' -p '\n",
    "spec:\n",
    "  nodeSets:\n",
    "  - name: data-node\n",
    "    config:\n",
    "      vectors.indexing.use_gpu: true\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e26764",
   "metadata": {},
   "source": [
    "## Check GPU is Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0dec3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl logs elastic-es-data-node-0 -c elasticsearch | grep \"Found compatible GPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31604b27",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_latencies, gpu_throughputs = speed_test()\n",
    "print('Latencies:', cpu_latencies)\n",
    "print('Throughputs:', cpu_throughputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9e2fb",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9632c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_latencies = pd.DataFrame({\n",
    "    'CPU': cpu_latencies,\n",
    "    'GPU': gpu_latencies\n",
    "})\n",
    "df_throughputs = pd.DataFrame({\n",
    "    'CPU': cpu_throughputs,\n",
    "    'GPU': gpu_throughputs\n",
    "})\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "df_latencies.quantile(0.95).plot(kind='bar', ax=ax1, color=colors, rot=0)\n",
    "ax1.set_title('Latency (P95)\\nLower is better', fontweight='bold')\n",
    "ax1.set_ylabel('Seconds')\n",
    "\n",
    "df_throughputs.mean().plot(kind='bar', ax=ax2, color=colors, rot=0)\n",
    "ax2.set_title('Throughput (Mean)\\nHigher is better', fontweight='bold')\n",
    "ax2.set_ylabel('Requests per Second')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45932b0",
   "metadata": {},
   "source": [
    "## Destroy Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b95ab6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting cluster gpu-demo...\n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Deleted [https://container.googleapis.com/v1/projects/elastic-customer-eng/zones/us-central1/clusters/gpu-demo].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -f .env\n",
    "rm -f ca.crt\n",
    "gcloud container clusters delete gpu-demo \\\n",
    "--region us-central1 \\\n",
    "--quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
