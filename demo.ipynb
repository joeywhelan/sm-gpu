{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44328d25",
   "metadata": {},
   "source": [
    "# Elastic/Nvidia GPU Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421faf3",
   "metadata": {},
   "source": [
    "## Create GKE Cluster + GPU Node Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7907e8e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).\n",
      "Creating cluster gpu-demo in us-central1...\n",
      "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Created [https://container.googleapis.com/v1/projects/elastic-customer-eng/zones/us-central1/clusters/gpu-demo].\n",
      "To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1/gpu-demo?project=elastic-customer-eng\n",
      "kubeconfig entry generated for gpu-demo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      LOCATION     MASTER_VERSION      MASTER_IP      MACHINE_TYPE   NODE_VERSION        NUM_NODES  STATUS   STACK_TYPE\n",
      "gpu-demo  us-central1  1.34.3-gke.1051003  34.46.172.208  e2-standard-4  1.34.3-gke.1051003  3          RUNNING  IPV4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Modifications on the boot disks of node VMs do not persist across node recreations. Nodes are recreated during manual-upgrade, auto-upgrade, auto-repair, and auto-scaling. To preserve modifications across node recreation, use a DaemonSet.\n",
      "Note: Machines with GPUs have certain limitations which may affect your workflow. Learn more at https://cloud.google.com/kubernetes-engine/docs/how-to/gpus\n",
      "Note: Starting in GKE 1.30.1-gke.115600, if you don't specify a driver version, GKE installs the default GPU driver for your node's GKE version.\n",
      "Creating node pool gpu-pool...\n",
      ".......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Created [https://container.googleapis.com/v1/projects/elastic-customer-eng/zones/us-central1/clusters/gpu-demo/nodePools/gpu-pool].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      MACHINE_TYPE   DISK_SIZE_GB  NODE_VERSION\n",
      "gpu-pool  g2-standard-4  100           1.34.3-gke.1051003\n",
      "NODE                                      ZONE\n",
      "gke-gpu-demo-default-pool-571f952a-sm3g   us-central1-a\n",
      "gke-gpu-demo-default-pool-b9d8fce9-22ls   us-central1-c\n",
      "gke-gpu-demo-default-pool-cf534126-pz85   us-central1-b\n",
      "gke-gpu-demo-gpu-pool-3b088dfc-4pwp       us-central1-a\n",
      "gke-gpu-demo-gpu-pool-6395e6ae-gntm       us-central1-b\n",
      "gke-gpu-demo-gpu-pool-a5e9250b-rmgg       us-central1-c\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud container clusters create gpu-demo \\\n",
    "    --region us-central1 \\\n",
    "    --node-locations us-central1-a,us-central1-b,us-central1-c \\\n",
    "    --num-nodes 1 \\\n",
    "    --machine-type e2-standard-4 \\\n",
    "    --disk-type pd-standard \\\n",
    "    --disk-size 50GB\n",
    "\n",
    "gcloud container node-pools create gpu-pool \\\n",
    "    --cluster gpu-demo \\\n",
    "    --region us-central1 \\\n",
    "    --node-locations us-central1-a,us-central1-b,us-central1-c \\\n",
    "    --num-nodes 1 \\\n",
    "    --enable-autoscaling \\\n",
    "    --total-min-nodes 3 \\\n",
    "    --total-max-nodes 6 \\\n",
    "    --machine-type g2-standard-4 \\\n",
    "    --disk-type pd-ssd \\\n",
    "    --disk-size 100GB \\\n",
    "    --image-type \"UBUNTU_CONTAINERD\" \\\n",
    "    --node-labels=\"gke-no-default-nvidia-gpu-device-plugin=true\" \\\n",
    "    --accelerator type=nvidia-l4,count=1 \\\n",
    "    --location-policy ANY \\\n",
    "    --spot\n",
    "\n",
    "kubectl get nodes -o custom-columns=\"NODE:.metadata.name,ZONE:.metadata.labels.topology\\.kubernetes\\.io/zone\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32553b96",
   "metadata": {},
   "source": [
    "## Deploy Nvidia GPU Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9cfbdfc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/gpu-operator created\n",
      "resourcequota/gpu-operator-quota created\n",
      "\"nvidia\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvidia\" chart repository\n",
      "...Successfully got an update from the \"elastic\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0207 13:59:46.426479  642287 warnings.go:107] \"Warning: spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: node-role.kubernetes.io/master is use \\\"node-role.kubernetes.io/control-plane\\\" instead\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: gpu-operator-1770497980\n",
      "LAST DEPLOYED: Sat Feb  7 13:59:42 2026\n",
      "NAMESPACE: gpu-operator\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "DESCRIPTION: Install complete\n",
      "TEST SUITE: None\n",
      "Waiting for GPU capacity to be registered on nodes...\n",
      "✅ Success: 3 nodes have active GPUs (Targeted: 3)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create ns gpu-operator\n",
    "kubectl apply -n gpu-operator -f manifests/gpu-operator-quota.yaml\n",
    "\n",
    "helm repo add nvidia https://helm.ngc.nvidia.com/nvidia \\\n",
    "    && helm repo update\n",
    "helm install --wait --generate-name \\\n",
    "    -n gpu-operator --create-namespace \\\n",
    "    nvidia/gpu-operator \\\n",
    "    --version=v25.10.1 \\\n",
    "    --set toolkit.env[0].name=RUNTIME_CONFIG_SOURCE \\\n",
    "    --set toolkit.env[0].value=file\n",
    "\n",
    "echo \"Waiting for GPU capacity to be registered on nodes...\"\n",
    "\n",
    "while true; do\n",
    "    DESIRED=$(kubectl get pods -n gpu-operator -l app=nvidia-driver-daemonset --no-headers 2>/dev/null | wc -l)\n",
    "    READY_COUNT=$(kubectl get nodes -o custom-columns=CAP:.status.capacity.'nvidia\\.com/gpu' --no-headers 2>/dev/null | grep -v '<none>' | grep -v '^0$' | wc -l)\n",
    "    DESIRED=$(echo \"$DESIRED\" | tr -d ' ')\n",
    "    READY_COUNT=$(echo \"$READY_COUNT\" | tr -d ' ')\n",
    "\n",
    "    if [ \"$DESIRED\" -gt 0 ] && [ \"$READY_COUNT\" -ge \"$DESIRED\" ]; then\n",
    "        echo \"✅ Success: $READY_COUNT nodes have active GPUs (Targeted: $DESIRED)\"\n",
    "        break\n",
    "    fi\n",
    "    sleep 5\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32287b7d",
   "metadata": {},
   "source": [
    "## Deploy Elastic Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "453dde40",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/eck-trial-license created\n",
      "elasticsearch.elasticsearch.k8s.elastic.co/elastic created\n",
      "kibana.kibana.k8s.elastic.co/kibana created\n",
      "⏳ Waiting for Elasticsearch (elastic-es-data-node) to be fully ready...\n",
      "✅ Elasticsearch is Ready.\n",
      "⏳ Waiting for Kibana to rollout...\n",
      "Waiting for deployment \"kibana-kb\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"kibana-kb\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"kibana-kb\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"kibana-kb\" successfully rolled out\n",
      "✅ Kibana is Ready.\n",
      "\n",
      "Pod: elastic-es-data-node-0       Zone: us-central1-b    Node: gke-gpu-demo-gpu-pool-6395e6ae-gntm\n",
      "Pod: elastic-es-data-node-1       Zone: us-central1-a    Node: gke-gpu-demo-gpu-pool-3b088dfc-4pwp\n",
      "Pod: elastic-es-data-node-2       Zone: us-central1-c    Node: gke-gpu-demo-gpu-pool-a5e9250b-rmgg\n",
      "Pod: elastic-es-master-node-0     Zone: us-central1-b    Node: gke-gpu-demo-default-pool-cf534126-pz85\n",
      "Pod: elastic-es-master-node-1     Zone: us-central1-a    Node: gke-gpu-demo-default-pool-571f952a-sm3g\n",
      "Pod: elastic-es-master-node-2     Zone: us-central1-c    Node: gke-gpu-demo-default-pool-b9d8fce9-22ls\n",
      "Pod: kibana-kb-9cb548746-x6bz5    Zone: us-central1-b    Node: gke-gpu-demo-default-pool-cf534126-pz85\n",
      "Pod: kibana-kb-d759fc44c-5j6r7    Zone: us-central1-a    Node: gke-gpu-demo-default-pool-571f952a-sm3g\n",
      "\n",
      "Kibana is available at: https://34.134.136.204:5601\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create -f https://download.elastic.co/downloads/eck/3.3.0/crds.yaml > /dev/null 2>&1\n",
    "kubectl apply -f https://download.elastic.co/downloads/eck/3.3.0/operator.yaml > /dev/null 2>&1\n",
    "kubectl apply -f manifests/es.yaml\n",
    "kubectl apply -f manifests/kb.yaml\n",
    "\n",
    "STS_NAME=\"elastic-es-data-node\"\n",
    "echo \"⏳ Waiting for Elasticsearch ($STS_NAME) to be fully ready...\"\n",
    "while ! kubectl get statefulset $STS_NAME > /dev/null 2>&1; do sleep 2; done\n",
    "\n",
    "until kubectl get statefulset $STS_NAME -o json | jq -e '\n",
    "   .status.readyReplicas == .spec.replicas and \n",
    "   .status.updatedReplicas == .spec.replicas' > /dev/null; do\n",
    "    sleep 5\n",
    "done\n",
    "echo \"✅ Elasticsearch is Ready.\"\n",
    "\n",
    "KB_DEPLOYMENT_NAME=\"kibana-kb\" \n",
    "echo \"⏳ Waiting for Kibana to rollout...\"\n",
    "while ! kubectl get deployment $KB_DEPLOYMENT_NAME > /dev/null 2>&1; do sleep 2; done\n",
    "kubectl rollout status deployment/$KB_DEPLOYMENT_NAME --timeout=300s\n",
    "echo \"✅ Kibana is Ready.\"\n",
    "\n",
    "cat > .env << EOF\n",
    "ELASTIC_USERNAME=elastic\n",
    "ELASTIC_PASSWORD=$(kubectl get secret elastic-es-elastic-user -o go-template='{{.data.elastic | base64decode}}')\n",
    "ELASTIC_URL=https://$(kubectl get svc elastic-es-http -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):9200\n",
    "EOF\n",
    "kubectl get secret elastic-es-http-certs-public -o jsonpath='{.data.ca\\.crt}' | base64 --decode > ca.crt\n",
    "\n",
    "echo\n",
    "kubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.nodeName}{\"\\t\"}{.metadata.labels.app}{\"\\n\"}{end}' | while read pod node app; do\n",
    "    zone=$(kubectl get node $node -o jsonpath='{.metadata.labels.topology\\.kubernetes\\.io/zone}')\n",
    "    echo \"Pod: $pod | Zone: $zone | Node: $node\"\n",
    "done | column -t -s \"|\"\n",
    "echo\n",
    "echo \"Kibana is available at: https://$(kubectl get svc kibana-kb-http -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):5601\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44943b08",
   "metadata": {},
   "source": [
    "## Confirm Elastic Detects GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fc1f936",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"@timestamp\":\"2026-02-07T21:14:59.867Z\",\"log.level\": \"INFO\",\"message\":\"Found compatible GPU [NVIDIA L4] (id: [0])\", \"ecs.version\": \"1.2.0\",\"service.name\":\"ES_ECS\",\"event.dataset\":\"elasticsearch.server\",\"process.thread.name\":\"main\",\"log.logger\":\"org.elasticsearch.gpu.GPUSupport\",\"elasticsearch.node.name\":\"elastic-es-data-node-0\",\"elasticsearch.cluster.name\":\"${sys:es.logs.cluster_name}\"}\n"
     ]
    }
   ],
   "source": [
    "! kubectl logs elastic-es-data-node-0 -c elasticsearch | grep \"NVIDIA\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c9d88",
   "metadata": {},
   "source": [
    "## Configure EIS for Self-Managed\n",
    "https://www.elastic.co/docs/explore-analyze/elastic-inference/connect-self-managed-cluster-to-eis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d28f3",
   "metadata": {},
   "source": [
    "## Install Python Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5abda633",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -q -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866a0e9",
   "metadata": {},
   "source": [
    "## Create Index + Semantic Search with Jina on EIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba7a3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 documents indexed.\n",
      "\n",
      "Query: Mit dauern andere der. Dein Schiff Minutenmir neun Winter. Gab Abend Mutter schwer Minute.\n",
      "\n",
      "Top 5 results:\n",
      "Score: 0.6585 | Text: Darauf Mutter bauen böse Woche. Nur Apfel baden um. Brauchen...\n",
      "Score: 0.6519 | Text: Bruder schicken ein her wollen nennen. Tante fehlen von Esse...\n",
      "Score: 0.6419 | Text: Toi naturel respect passé petit haute. Voiture lien marier p...\n",
      "Score: 0.6245 | Text: Depuis votre voix tombe surveiller midi tout. Circonstance p...\n",
      "Score: 0.6238 | Text: Natürlich ließ wollen auf dort. Dich fast Meer....\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from faker import Faker\n",
    "import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk, pack_dense_vector\n",
    "\n",
    "DATASET_SIZE = 150\n",
    "BATCH_SIZE = 15\n",
    "INDEX_NAME = \"jina_index\"\n",
    "\n",
    "faker = Faker(['en_US', 'es_ES', 'fr_FR', 'de_DE', 'zh_CN']) \n",
    "faker.seed_instance(12345)\n",
    "\n",
    "load_dotenv(override=True)\n",
    "es = Elasticsearch(\n",
    "    hosts=os.getenv(\"ELASTIC_URL\"),\n",
    "    basic_auth=(os.getenv(\"ELASTIC_USERNAME\"), os.getenv(\"ELASTIC_PASSWORD\")),\n",
    "    ca_certs=\"./ca.crt\"\n",
    ")\n",
    "\n",
    "settings = {\n",
    "    \"index\": {\n",
    "        \"number_of_shards\": 3,\n",
    "        \"number_of_replicas\": 1\n",
    "    }\n",
    "}\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"paragraph\": { \n",
    "            \"type\": \"text\" \n",
    "        },\n",
    "        \"embedding\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 1024,\n",
    "            \"index_options\": { \n",
    "                \"type\": \"int8_hnsw\" \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}  \n",
    "\n",
    "es.options(ignore_status=[404]).indices.delete(index=INDEX_NAME)\n",
    "es.indices.create(index=INDEX_NAME, body={\"settings\": settings, \"mappings\": mappings})\n",
    "\n",
    "def get_jina_embeddings(batch):\n",
    "    response = es.inference.inference(input=batch, inference_id=\".jina-embeddings-v3\")\n",
    "    return [item['embedding'] for item in response['text_embedding']]\n",
    "\n",
    "def generate_actions():\n",
    "    for _ in tqdm.tqdm(range(DATASET_SIZE // BATCH_SIZE)):\n",
    "        paragraphs = [faker.paragraph() for _ in range(BATCH_SIZE)]\n",
    "        embeddings = get_jina_embeddings(paragraphs)\n",
    "        for paragraph, embedding in zip(paragraphs, embeddings):\n",
    "            yield {\n",
    "                \"paragraph\": paragraph, \n",
    "                \"embedding\": pack_dense_vector(embedding)\n",
    "            }\n",
    "\n",
    "ok, result = bulk(client=es, index=INDEX_NAME, actions=generate_actions())\n",
    "print(f\"{ok} documents indexed.\")\n",
    "es.indices.refresh(index=INDEX_NAME)\n",
    "\n",
    "query_str = faker['de_DE'].paragraph()\n",
    "query_embedding = get_jina_embeddings([query_str])[0]\n",
    "response = es.search(\n",
    "    index = INDEX_NAME,\n",
    "    knn = {\n",
    "        \"field\": \"embedding\",\n",
    "        \"query_vector\": query_embedding,\n",
    "        \"k\": 5\n",
    "    },\n",
    "    source=[\"paragraph\"]\n",
    ")\n",
    "print(\"\\nQuery:\", query_str)\n",
    "print(\"\\nTop 5 results:\")\n",
    "for hit in response['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    paragraph = hit['_source']['paragraph']\n",
    "    print(f\"Score: {score:.4f} | Text: {paragraph[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16ae45",
   "metadata": {},
   "source": [
    "## Verify Elastic GPU Usage via NVIDIA SMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "974659c4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb  7 21:31:11 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   50C    P0             34W /   72W |     308MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             108      C   ...re/elasticsearch/jdk/bin/java        188MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! kubectl exec elastic-es-data-node-0 -c elasticsearch -- nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45932b0",
   "metadata": {},
   "source": [
    "## Destroy Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7b95ab6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting cluster gpu-demo...\n",
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Deleted [https://container.googleapis.com/v1/projects/elastic-customer-eng/zones/us-central1/clusters/gpu-demo].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -f .env\n",
    "rm -f ca.crt\n",
    "gcloud container clusters delete gpu-demo \\\n",
    "--region us-central1 \\\n",
    "--quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
