{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44328d25",
   "metadata": {},
   "source": [
    "# Elastic Self-Managed GPU Acceleration Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421faf3",
   "metadata": {},
   "source": [
    "## Create GKE Cluster + Node Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7907e8e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud container clusters create gpu-demo \\\n",
    "    --region us-central1 \\\n",
    "    --node-locations us-central1-a,us-central1-b,us-central1-c \\\n",
    "    --num-nodes 1 \\\n",
    "    --machine-type e2-standard-4 \\\n",
    "    --disk-type pd-standard \\\n",
    "    --disk-size 50GB\n",
    "\n",
    "gcloud container node-pools create gpu-pool \\\n",
    "    --cluster gpu-demo \\\n",
    "    --region us-central1 \\\n",
    "    --node-locations us-central1-a,us-central1-b,us-central1-c \\\n",
    "    --num-nodes 1 \\\n",
    "    --machine-type g2-standard-4 \\\n",
    "    --disk-type pd-ssd \\\n",
    "    --disk-size 50GB \\\n",
    "    --accelerator type=nvidia-l4,count=1,gpu-driver-version=latest \\\n",
    "    --location-policy ANY \\\n",
    "    --spot\n",
    "\n",
    "kubectl get nodes -o custom-columns=\"NODE:.metadata.name,ZONE:.metadata.labels.topology\\.kubernetes\\.io/zone\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32287b7d",
   "metadata": {},
   "source": [
    "## Deploy Elastic Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453dde40",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl create -f https://download.elastic.co/downloads/eck/3.2.0/crds.yaml > /dev/null 2>&1\n",
    "kubectl apply -f https://download.elastic.co/downloads/eck/3.2.0/operator.yaml > /dev/null 2>&1\n",
    "kubectl apply -f manifests\n",
    "ES_STATUS=$(kubectl get elasticsearch -o=jsonpath='{.items[0].status.health}')\n",
    "KB_STATUS=$(kubectl get kibana -o=jsonpath='{.items[0].status.health}')\n",
    "while [[ $ES_STATUS != \"green\" ||  $KB_STATUS != \"green\" ]]\n",
    "do  \n",
    "  sleep 5\n",
    "  ES_STATUS=$(kubectl get elasticsearch -o=jsonpath='{.items[0].status.health}')\n",
    "  KB_STATUS=$(kubectl get kibana -o=jsonpath='{.items[0].status.health}')\n",
    "done\n",
    "\n",
    "cat > .env << EOF\n",
    "ELASTIC_USERNAME=elastic\n",
    "ELASTIC_PASSWORD=$(kubectl get secret elastic-es-elastic-user -o go-template='{{.data.elastic | base64decode}}')\n",
    "ELASTIC_URL=https://$(kubectl get svc elastic-es-http -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):9200\n",
    "EOF\n",
    "\n",
    "cat .api_keys >> .env 2>/dev/null\n",
    "kubectl get secret elastic-es-http-certs-public -o jsonpath='{.data.ca\\.crt}' | base64 --decode > ca.crt\n",
    "\n",
    "echo\n",
    "kubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.nodeName}{\"\\t\"}{.metadata.labels.app}{\"\\n\"}{end}' | while read pod node app; do\n",
    "    zone=$(kubectl get node $node -o jsonpath='{.metadata.labels.topology\\.kubernetes\\.io/zone}')\n",
    "    echo \"Pod: $pod | Zone: $zone | Node: $node\"\n",
    "done | column -t -s \"|\"\n",
    "echo\n",
    "echo \"Kibana is available at: https://$(kubectl get svc kibana-kb-http -o jsonpath='{.status.loadBalancer.ingress[0].ip}'):5601\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866a0e9",
   "metadata": {},
   "source": [
    "## Create Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from faker import Faker\n",
    "import requests \n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "DATASET_SIZE = 10000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "class RateLimitError(Exception):\n",
    "    pass\n",
    "\n",
    "@retry(\n",
    "        wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "        stop=stop_after_attempt(5),\n",
    "        retry=retry_if_exception_type(RateLimitError)\n",
    ")\n",
    "def get_jina_embeddings(batch):\n",
    "    url = \"https://api.jina.ai/v1/embeddings\"\n",
    "    headers = { \n",
    "        \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\", \n",
    "        \"Content-Type\": \"application/json\" \n",
    "    }\n",
    "    payload = { \n",
    "        \"model\": \"jina-embeddings-v3\", \n",
    "        \"task\": \"text-matching\",\n",
    "        \"input\": batch\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 429:\n",
    "        raise RateLimitError(\"Rate limit exceeded\")\n",
    "    response.raise_for_status()\n",
    "    return [item['embedding'] for item in response.json()['data']]\n",
    "\n",
    "def create_data_file():\n",
    "    fake = Faker()\n",
    "    fake.seed_instance(12345)\n",
    "\n",
    "    with open(\"data.jsonl\", \"w\") as f:\n",
    "        for _ in tqdm.tqdm(range(DATASET_SIZE // BATCH_SIZE)):\n",
    "            paragraphs = fake.paragraphs(nb=BATCH_SIZE)\n",
    "            embeddings = get_jina_embeddings(paragraphs)\n",
    "            for paragraph, embedding in zip(paragraphs, embeddings):\n",
    "                doc = {\"paragraph\": paragraph, \"embedding\": embedding}\n",
    "                f.write(json.dumps(doc) + \"\\n\")\n",
    "            time.sleep(1) \n",
    "\n",
    "if not os.path.exists(\"data.jsonl\"):\n",
    "    create_data_file()\n",
    "\n",
    "with open(\"data.jsonl\", \"r\") as f:\n",
    "    line_count = sum(1 for _ in f)\n",
    "print(f'{line_count} documents on file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bce783",
   "metadata": {},
   "source": [
    "## Index Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb80187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "INDEX_NAME = \"test_index\"\n",
    "es = Elasticsearch(\n",
    "    hosts=os.getenv(\"ELASTIC_URL\"),\n",
    "    basic_auth=(os.getenv(\"ELASTIC_USERNAME\"), os.getenv(\"ELASTIC_PASSWORD\")),\n",
    "    ca_certs=\"./ca.crt\"\n",
    ")\n",
    "\n",
    "settings = {\n",
    "    \"index\": {\n",
    "        \"number_of_shards\": 3,\n",
    "        \"number_of_replicas\": 1\n",
    "    }\n",
    "}\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"paragraph\": { \"type\": \"text\" },\n",
    "        \"embedding\": {\n",
    "            \"type\": \"dense_vector\",\n",
    "            \"dims\": 1024,\n",
    "            \"index\": True,\n",
    "            \"index_options\": {\n",
    "                \"type\": \"int8_hnsw\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}            \n",
    "\n",
    "es.options(ignore_status=[404]).indices.delete(index=INDEX_NAME)\n",
    "es.indices.create(index=INDEX_NAME, body={\"settings\": settings, \"mappings\": mappings})\n",
    "\n",
    "def gen_data():\n",
    "    with open(\"data.jsonl\", \"r\") as f:\n",
    "        for line in f:\n",
    "            yield line.strip()\n",
    "            \n",
    "ok, result = helpers.bulk(client=es, index=INDEX_NAME, actions=gen_data())\n",
    "print(f\"{ok} documents indexed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708c495",
   "metadata": {},
   "source": [
    "## Reindex Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6529cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*technical preview.*\")\n",
    "\n",
    "def monitor_reindex(task_id):\n",
    "    while True:\n",
    "        task = es.tasks.get(task_id=task_id)\n",
    "        completed = task.get('completed', False)\n",
    "        if completed:\n",
    "            latency_sec = task['response']['took'] / 1000\n",
    "            total_docs = task['response']['total']\n",
    "            throughput = total_docs / latency_sec\n",
    "            return latency_sec, throughput\n",
    "        time.sleep(2)\n",
    "            \n",
    "def speed_test(tests=5):\n",
    "    latencies = []\n",
    "    throughputs = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(tests)):\n",
    "        es.indices.clear_cache(index=INDEX_NAME)\n",
    "        dest = f\"{INDEX_NAME}_{uuid.uuid4()}\"\n",
    "        reindex_body = {\n",
    "            \"source\": { \"index\": INDEX_NAME },\n",
    "            \"dest\": { \"index\": dest }\n",
    "        }\n",
    "        response = es.reindex(slices=\"auto\", body=reindex_body, wait_for_completion=False)\n",
    "        task_id = response['task']\n",
    "        latency, throughput = monitor_reindex(task_id)\n",
    "        latencies.append(latency)\n",
    "        throughputs.append(throughput)\n",
    "        es.indices.delete(index=dest)\n",
    "        if i < tests - 1:\n",
    "            time.sleep(30)\n",
    "    return latencies, throughputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f753b70",
   "metadata": {},
   "source": [
    "## CPU Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af28637",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_latencies, cpu_throughputs = speed_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c638f",
   "metadata": {},
   "source": [
    "## Reconfigure for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f213b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31604b27",
   "metadata": {},
   "source": [
    "## GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_latencies, gpu_throughputs = speed_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9e2fb",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9632c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_latencies = pd.DataFrame({\n",
    "    'CPU': cpu_latencies,\n",
    "    'GPU': gpu_latencies\n",
    "})\n",
    "df_throughputs = pd.DataFrame({\n",
    "    'CPU': cpu_throughputs,\n",
    "    'GPU': gpu_throughputs\n",
    "})\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "df_latencies.quantile(0.95).plot(kind='bar', ax=ax1, color=colors, rot=0)\n",
    "ax1.set_title('Latency (P95)\\nLower is better', fontweight='bold')\n",
    "ax1.set_ylabel('Seconds')\n",
    "\n",
    "df_throughputs.mean().plot(kind='bar', ax=ax2, color=colors, rot=0)\n",
    "ax2.set_title('Throughput (Mean)\\nHigher is better', fontweight='bold')\n",
    "ax2.set_ylabel('Requests per Second')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45932b0",
   "metadata": {},
   "source": [
    "## Destroy Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b95ab6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f .env\n",
    "rm -f ca.crt\n",
    "gcloud container clusters delete gpu-demo \\\n",
    "--region us-central1 \\\n",
    "--quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
